{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-27T14:03:05.473781Z",
     "iopub.status.busy": "2024-10-27T14:03:05.472179Z",
     "iopub.status.idle": "2024-10-27T14:05:05.4634Z",
     "shell.execute_reply": "2024-10-27T14:05:05.46188Z",
     "shell.execute_reply.started": "2024-10-27T14:03:05.473712Z"
    },
    "id": "D7_S0W5sVFIn",
    "outputId": "f308765e-c28c-49a6-c6c9-773cd84f6786",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip install llama-index-core\n",
    "!pip install llama-index-llms-lmstudio\n",
    "!pip install llama-index-embeddings-huggingface\n",
    "!pip install llama-index-llms-huggingface\n",
    "!pip install llama-index-llms-huggingface-api\n",
    "!pip install huggingface-hub\n",
    "!pip install \"transformers[torch]\" \"huggingface_hub[inference]\"\n",
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2024-10-27T14:05:05.466849Z",
     "iopub.status.busy": "2024-10-27T14:05:05.466376Z",
     "iopub.status.idle": "2024-10-27T14:05:10.699891Z",
     "shell.execute_reply": "2024-10-27T14:05:10.698415Z",
     "shell.execute_reply.started": "2024-10-27T14:05:05.4668Z"
    },
    "id": "Ci3fXkT6VFIn",
    "outputId": "7d6cd93f-bdec-4b6f-d3df-88dbe621b95c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "from huggingface_hub import login\n",
    "import pandas as pd\n",
    "from llama_index.llms.huggingface_api import HuggingFaceInferenceAPI\n",
    "from llama_index.core import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-10-27T14:05:11.817674Z",
     "iopub.status.idle": "2024-10-27T14:05:11.818274Z",
     "shell.execute_reply": "2024-10-27T14:05:11.817997Z",
     "shell.execute_reply.started": "2024-10-27T14:05:11.817965Z"
    },
    "id": "ZzSDfJgFVFIp",
    "outputId": "82381370-befd-46ee-9add-3bf89d7705a6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "hfToken = getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-10-27T14:05:11.821065Z",
     "iopub.status.idle": "2024-10-27T14:05:11.821544Z",
     "shell.execute_reply": "2024-10-27T14:05:11.821297Z",
     "shell.execute_reply.started": "2024-10-27T14:05:11.821277Z"
    },
    "id": "of9AV0nSVFIp",
    "outputId": "1b1462c7-c426-4ea7-cb92-50f9cef867bd",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "login(token=hfToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-27T14:05:11.822673Z",
     "iopub.status.idle": "2024-10-27T14:05:11.823114Z",
     "shell.execute_reply": "2024-10-27T14:05:11.822923Z",
     "shell.execute_reply.started": "2024-10-27T14:05:11.822901Z"
    },
    "id": "rupl-E4VVFIp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = 'mistralai/Mixtral-8x7B-Instruct-v0.1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-27T14:05:11.824669Z",
     "iopub.status.idle": "2024-10-27T14:05:11.825079Z",
     "shell.execute_reply": "2024-10-27T14:05:11.824896Z",
     "shell.execute_reply.started": "2024-10-27T14:05:11.824876Z"
    },
    "id": "HQyNzqmTVFIp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "llm = HuggingFaceInferenceAPI(model_name=model, token=hfToken)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-10-27T14:05:11.826662Z",
     "iopub.status.idle": "2024-10-27T14:05:11.827075Z",
     "shell.execute_reply": "2024-10-27T14:05:11.826893Z",
     "shell.execute_reply.started": "2024-10-27T14:05:11.826873Z"
    },
    "id": "psvc1cK8VFIp",
    "outputId": "b9c6fa0e-ff32-404a-c4a9-ebeec9826683",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-27T14:05:11.82838Z",
     "iopub.status.idle": "2024-10-27T14:05:11.828832Z",
     "shell.execute_reply": "2024-10-27T14:05:11.828636Z",
     "shell.execute_reply.started": "2024-10-27T14:05:11.828613Z"
    },
    "id": "h8xhyYIhVFIp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "template = (\n",
    "    \"The context information is below. \\n\"\n",
    "    \"---------------------\\n\"\n",
    "    \"{context_str}\"\n",
    "    \"\\n---------------------\\n\"\n",
    "    \"Given this information, please answer the question: {query_str}\\n\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-27T14:05:11.830784Z",
     "iopub.status.idle": "2024-10-27T14:05:11.831201Z",
     "shell.execute_reply": "2024-10-27T14:05:11.831018Z",
     "shell.execute_reply.started": "2024-10-27T14:05:11.830997Z"
    },
    "id": "mKb40yzkVFIp",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "qa_template = PromptTemplate(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-10-27T14:05:11.83254Z",
     "iopub.status.idle": "2024-10-27T14:05:11.832997Z",
     "shell.execute_reply": "2024-10-27T14:05:11.8328Z",
     "shell.execute_reply.started": "2024-10-27T14:05:11.832777Z"
    },
    "id": "YDQOkbN1VFIp",
    "outputId": "d093575d-e81e-4720-b4fd-786624de3c0c",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "qa_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-10-27T14:05:11.834386Z",
     "iopub.status.idle": "2024-10-27T14:05:11.834812Z",
     "shell.execute_reply": "2024-10-27T14:05:11.834627Z",
     "shell.execute_reply.started": "2024-10-27T14:05:11.834604Z"
    },
    "id": "Q4RSy_B1VFIp",
    "outputId": "f93f27ba-b8f1-4b92-8a31-f4996c23f538",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# text = df['content'].iloc[3]\n",
    "text = \"\"\"\n",
    "TEL AVIV, Israel — Israel attacked military targets in Iran with a series of pre-dawn airstrikes Saturday in retaliation for the barrage of ballistic missiles the Islamic Republic fired upon Israel earlier in the month.\n",
    "\n",
    "The Israeli military said its aircraft targeted facilities that Iran used to make the missiles fired at Israel as well as surface-to-air missile sites. There was no immediate indication that oil or missile sites were hit — strikes that would have marked a much more serious escalation — and Israel offered no immediate damage assessment.\n",
    "\n",
    "Explosions could be heard in the Iranian capital, Tehran, though the Islamic Republic insisted they caused only “limited damage” and Iranian state-run media downplayed the attacks. Iran's army said two of its troops had been killed in the attack, Iran's Al-Alam television reported.\n",
    "\n",
    "Still, the strikes risk pushing the archenemies closer to all-out war at a time of spiraling violence across the Middle East, where militant groups backed by Iran — including Hamas in Gaza and Hezbollah in Lebanon — are already at war with Israel.\n",
    "\n",
    "Following the airstrikes, Iran's Foreign Ministry issued a statement saying it had a right to self-defense, and \"considers itself entitled and obligated to defend against foreign acts of aggression.\"\n",
    "\n",
    "The first open Israeli attack on Iran\n",
    "“Iran attacked Israel twice, including in locations that endangered civilians, and has paid the price for it,” said Israeli military spokesperson Rear Adm. Daniel Hagari.\n",
    "\n",
    "“We are focused on our war objectives in the Gaza Strip and Lebanon. It is Iran that continues to push for a wider regional escalation.”\n",
    "\n",
    "Photos and video released by Israel showed Prime Minister Benjamin Netanyahu, wearing a black casual jacket, and Defense Minister Yoav Gallant meeting with military advisers and others in a conference room at a military command and control center in the Kirya military base in Tel Aviv.\n",
    "\n",
    "The strikes filled the air for hours until sunrise in Iran. They marked the first time Israel's military has openly attacked Iran, which hasn't faced a sustained barrage of fire from a foreign enemy since its 1980s war with Iraq.\n",
    "\n",
    "Israel is also widely thought to have been behind a limited airstrike in April near a major air base in Iran in which the radar system for a Russian-made air defense battery was hit.\n",
    "\n",
    "Saturday's attack came as part of Israel's “duty to respond” to attacks on it from “Iran and its proxies in the region,” Hagari said.\n",
    "\n",
    "“The Israel Defense Forces has fulfilled its mission,” Hagari said. “If the regime in Iran were to make the mistake of beginning a new round of escalation, we will be obligated to respond.”\n",
    "\n",
    "Israel’s attack effectively sent the message to Iran that it would not remain silent, while not taking out highly visible or symbolic facilities that could prompt an significant response from Iran, said Yoel Guzansky, a researcher at Tel Aviv's Institute for National Security Studies who formerly worked for Israel’s National Security Council.\n",
    "\n",
    "At the same time, it also gives Israel room for further escalation if needed, and the targeting of air defense systems weakens Iran’s capabilities to defend against future attacks, he said, adding that if there is Iranian retaliation, he expects it to be limited.\n",
    "\n",
    "“There’s more chances of Iranian restraint because of their interests, because of pressure from the outside, and because of the nature of the Israeli attack … that allows them to save face,” he said.\n",
    "\n",
    "In the aftermath of the strikes, the streets of the Iranian capital were calm, children went to school and shops opened as usual, with the only sign of concern being long lines at the gas stations — a regular occurrence in Tehran when military violence flares or during natural disasters when people stock up on fuel.\n",
    "\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-10-27T14:05:11.836875Z",
     "iopub.status.idle": "2024-10-27T14:05:11.837292Z",
     "shell.execute_reply": "2024-10-27T14:05:11.83711Z",
     "shell.execute_reply.started": "2024-10-27T14:05:11.83709Z"
    },
    "id": "Vf6L6JXiVFIq",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "q = \"\"\"\n",
    "I need you to analyze a given news article and determine its political bias using the following ratings:\n",
    "\n",
    "1. **Far Left**: Strongly biased toward liberal causes, reflecting extreme left-leaning policy positions. Uses strong, emotional language and may publish misleading reports or omit information unfavorable to liberal causes.\n",
    "2. **Left**: Moderately biased toward liberal causes, reflecting current positions of left-leaning party leaders. May use loaded words or omit information unfavorable to liberal causes.\n",
    "3. **Lean Left**: Slight to moderate liberal bias. Generally factual but may use language favoring liberal causes.\n",
    "4. **Center**: No discernable political position. Uses few loaded words, well-sourced reporting, and presents a relatively complete survey of competing positions on issues.\n",
    "5. **Lean Right**: Slight to moderate conservative bias. Generally factual but may use language favoring conservative causes.\n",
    "6. **Right**: Moderately biased toward conservative causes, reflecting current positions of right-leaning party leaders. May publish misleading reports or omit information unfavorable to conservative causes.\n",
    "7. **Far Right**: Strongly biased toward conservative causes, reflecting extreme right-leaning policy positions. Uses strong, emotional language and may publish misleading reports or omit information unfavorable to conservative causes.\n",
    "\n",
    "Please provide a descriptive explanation of why you chose a particular side, citing specific examples from the text that demonstrate its alignment with the given ratings. Additionally, highlight whether any key topics (e.g., immigration, healthcare, economy) are presented in a biased manner, noting the use of emotionally charged language or omissions of critical facts.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.status.busy": "2024-10-27T14:05:11.838475Z",
     "iopub.status.idle": "2024-10-27T14:05:11.83892Z",
     "shell.execute_reply": "2024-10-27T14:05:11.838726Z",
     "shell.execute_reply.started": "2024-10-27T14:05:11.838703Z"
    },
    "id": "hWHg22uzVFIq",
    "outputId": "0daa56d3-62fa-4c34-e7bb-605ae42e3dfb",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "prompt = qa_template.format(context_str = text, query_str=q)\n",
    "response = llm.complete(prompt)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "485NpqiNWVCf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4008801,
     "sourceId": 6976342,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30786,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
